{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DICT = '/Users/anne/repos/RPA/resources/'\n",
    "FILENAME_DICT = '20140718_dutchdictionary.txt'\n",
    "PATH_TO_DATA = '~/surfdrive/uva/projects/RPA_KeepingScore/pickle_files/'\n",
    "\n",
    "MINNUMBERMATCHES = 2 # min number of times a keyword should occur for a topic to be present\n",
    "\n",
    "stemmer = SnowballStemmer(\"dutch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_topic(x):\n",
    "    if x == '1':\n",
    "        return 'Macro-economie en belastingen'\n",
    "    if x == '2':\n",
    "        return 'Burgerrechten en vrijheden'\n",
    "    if x == '3':\n",
    "        return 'Gezondheid'\n",
    "    if x == '4':\n",
    "        return 'Landbouw en Visserij'\n",
    "    if x == '5':\n",
    "        return 'Arbeid'\n",
    "    if x == '6':\n",
    "        return 'Onderwijs'\n",
    "    if x == '7':\n",
    "        return 'Milieu'\n",
    "    if x == '8':\n",
    "        return 'Energiebeleid'\n",
    "    if x == '9':\n",
    "        return 'Immigratie en integratie'\n",
    "    if x == '10':\n",
    "        return 'Verkeer en vervoer'\n",
    "    if x == '11':\n",
    "        return 'Unkown'\n",
    "    if x == '12':\n",
    "        return 'Justitie, Rechtspraak, Criminaliteit'\n",
    "    if x == '13':\n",
    "        return 'sociale Zaken'\n",
    "    if x == '14':\n",
    "        return 'Gemeenschapsontwikkeling, huisvestingsbeleid en stedelijke planning'\n",
    "    if x == '15':\n",
    "        return 'Ondernemingen, Bankwezen en binnenlandse handel '\n",
    "    if x == '16':\n",
    "        return 'Defensie'\n",
    "    if x == '17':\n",
    "        return 'Wetenschappelijk onderzoek, technologie en communicatie'\n",
    "    if x == '18':\n",
    "        return 'Buitenlandse handel'\n",
    "    if x == '19':\n",
    "        return 'Buitenlandse zaken en ontwikkelingssamenwerking'\n",
    "    if x == '20':\n",
    "        return 'Functioneren democratie en openbaar bestuur'\n",
    "    if x == '21':\n",
    "        return 'Ruimtelijke ordening, publiek natuur- en waterbeheer'\n",
    "    if x == '22':\n",
    "        return 'Unkown 2'\n",
    "    if x == '23':\n",
    "        return 'Kunst, cultuur en entertainment'\n",
    "    if x == '24':\n",
    "        return '*** Gemeentelijk en provinciaal bestuur'\n",
    "    if x == '29':\n",
    "        return '*** Sport'\n",
    "    if x == '00':\n",
    "        return 'Toegevoegde codes voor media'\n",
    "    \n",
    "def parse_xml():\n",
    "    '''reads file with topic numbers + words and parses the title'''\n",
    "    \n",
    "    words = []\n",
    "    topics = []\n",
    "    for l in [line.strip() for line in open(os.path.join(BASE_DICT , FILENAME_DICT)).readlines() if len(line)>1] :\n",
    "        topics_words = defaultdict(list)\n",
    "        if l.startswith('<cnode'):\n",
    "            wordlist = []\n",
    "            topics_l = list(re.sub('\">|\"|t', '', l.split('=')[1]) )\n",
    "            if len(topics_l) == 2 :\n",
    "                final_topic = \"\".join(topics_l)\n",
    "            elif len(topics_l) == 3 :\n",
    "                final_topic = topics_l[0]\n",
    "            elif len(topics_l) == 4 :\n",
    "                final_topic = \"\".join( topics_l[:2] )\n",
    "        elif l.startswith('<pnode'):\n",
    "            word = re.sub('\">|</pnode>|\"', '', l.split('=')[1]) \n",
    "            words.append(word)\n",
    "            topics.append(final_topic)\n",
    "    return words, topics\n",
    "\n",
    "def get_dict():\n",
    "    'returns a dict with keys = topic, values = words '\n",
    "    \n",
    "    words, topics = parse_xml()\n",
    "    d = defaultdict(list)\n",
    "    for topic, word in zip(topics, words):\n",
    "        topic_name = label_topic(topic)\n",
    "        d[topic_name].append(word)\n",
    "    return d\n",
    "\n",
    "def get_stemmed_dict():\n",
    "    stemmer = SnowballStemmer(\"dutch\")\n",
    "    d = get_dict()\n",
    "    stemmed_dictionary = {}\n",
    "    for topic, words in d.items():\n",
    "        stemmed_dictionary[topic] = [ stemmer.stem(w) for w in words ]\n",
    "    return stemmed_dictionary\n",
    "\n",
    "def get_raw_data():\n",
    "    df = pd.read_pickle(PATH_TO_DATA + 'VK_TEL')\n",
    "    df = df[['text_title', 'main_topic', 'main_topic_label']]\n",
    "    df.rename(columns={'text_title' : 'text', 'main_topic' : 'topic'}, inplace = True)\n",
    "    df['type'] = 'newspaper'\n",
    "    \n",
    "    df2 = pd.read_pickle(PATH_TO_DATA + 'kamervragen')\n",
    "    df2 = df2[['questions', 'main_topic', 'main_topic_label']]\n",
    "    df2.rename(columns={'questions' : 'text', 'main_topic' : 'topic'}, inplace = True)\n",
    "    df2['type'] = 'parlementary question'\n",
    "    \n",
    "    df = df.append(df2)\n",
    "    \n",
    "    df['origin'] = 'RPA'\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['documentnr'] = df.index\n",
    "    logger.info(\"Appended the kamervragen dataset to the newspaper dataset, resulting in a df with a len of {}\".format(len(df)))\n",
    "    return df\n",
    "\n",
    "def get_bjorn_data():\n",
    "    df = pd.read_pickle(PATH_TO_DATA + 'dataset_burscher.pkl')\n",
    "    df['origin'] = 'Bjorn'\n",
    "    df['type'] = 'newspaper'\n",
    "    return df\n",
    "    \n",
    "def get_recode_data():\n",
    "    '''match data according to coding of Bjorn '''\n",
    "    \n",
    "    df = get_raw_data()\n",
    "    a = ['Buitenlandse handel' , 'Kunst, cultuur en entertainment' ,  'Ruimtelijke ordening, publiek natuur- en waterbeheer', 'Toegevoegde codes voor media', None] \n",
    "    b = ['Overige' ] * len(a)\n",
    "    overige_cat = dict(zip(a,b))\n",
    "    df['main_topic_label'].replace(overige_cat, inplace = True)\n",
    "    logger.info(\"Recoded data according to Bjorn's dataset. New topic categories are: {}\".format(df['main_topic_label'].unique()))\n",
    "    return df\n",
    "\n",
    "def get_data():\n",
    "    df = get_recode_data().append(get_bjorn_data())\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['documentnr'] = df.index\n",
    "    logger.info(\"Retrieved the recoded dataset, merged with Bjorn's data, containing {} cases\".format(len(df)))\n",
    "    return df\n",
    "\n",
    "def stem_sentences(sentence):\n",
    "    try:\n",
    "        tokens = sentence.split()\n",
    "        stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "        return ' '.join(stemmed_tokens)\n",
    "    except:\n",
    "        return 'NAN'\n",
    "\n",
    "def return_stemmed_text_columns():\n",
    "    df = get_data()\n",
    "    logger.info(\"Start stemming....\")\n",
    "    df['stemmed_text'] = df.text.apply(stem_sentences)\n",
    "    return df\n",
    "\n",
    "def dictionary_topics():\n",
    "    df1 = return_stemmed_text_columns()\n",
    "    result = []\n",
    "    documentnr = -1\n",
    "    for document in df1['text']:\n",
    "        documentnr += 1\n",
    "        topics_per_document = {}\n",
    "        d = get_dict()\n",
    "        logger.info(\"Start word search....\")\n",
    "        for topic, words in d.items():\n",
    "            match = [x for x in words if x in document.lower().split(' ')]\n",
    "            doc_string = document.lower().split(' ')\n",
    "            index = [doc_string.index(word) for word in match ]\n",
    "            try:\n",
    "                index_smallest = min(index)\n",
    "            except:\n",
    "                index_smallest = np.nan\n",
    "\n",
    "            topics_per_document = {'documentnr' : documentnr, \n",
    "                                    'topic_label_dictionary': topic, \n",
    "                                    'index_words' : index, \n",
    "                                    'smallest_index' : index_smallest,\n",
    "                                    'len matches' : len(match),\n",
    "                                    'words matches' : match  ,\n",
    "                                    'text' : document.lower()}\n",
    "            result.append(topics_per_document)\n",
    "    return result\n",
    "\n",
    "def dictionary_topics_stemmed():\n",
    "    df1 = return_stemmed_text_columns()\n",
    "    result = []\n",
    "    documentnr = -1\n",
    "    for document in df1['stemmed_text']:\n",
    "        documentnr += 1\n",
    "        topics_per_document = {}\n",
    "        d = get_stemmed_dict()\n",
    "        logger.info(\"Start word search on stemmed text...\")\n",
    "        for topic, words in d.items():\n",
    "            match = [x for x in words if x in document.lower().split(' ')]\n",
    "            doc_string = document.lower().split(' ')\n",
    "            index = [doc_string.index(word) for word in match ]\n",
    "            try:\n",
    "                index_smallest = min(index)\n",
    "            except:\n",
    "                index_smallest = np.nan\n",
    "\n",
    "            topics_per_document = {'documentnr' : documentnr, \n",
    "                                    'stemmed_topic_label_dictionary': topic, \n",
    "                                    'stemmed_index_words' : index, \n",
    "                                    'stemmed_smallest_index' : index_smallest,\n",
    "                                    'stemmed_len matches' : len(match),\n",
    "                                    'stemmed_words matches' : match  ,\n",
    "                                    'stemmed_text' : document.lower()}\n",
    "            result.append(topics_per_document)\n",
    "    return result\n",
    "\n",
    "def get_merged_df():\n",
    "    '''returns a df with number of topics as identified by the dictionary approach'''\n",
    "    \n",
    "    result = dictionary_topics()\n",
    "    stemmed_results = dictionary_topics_stemmed()\n",
    "    df2 = pd.DataFrame.from_dict(result)\n",
    "    df2 = (df2.assign(to_sort = df2.smallest_index.abs()).sort_values('to_sort').drop_duplicates('documentnr').drop(columns='to_sort'))\n",
    "    df2 = df2[np.isfinite(df2['smallest_index'])]\n",
    "    df3 = pd.DataFrame.from_dict(stemmed_results)\n",
    "    df3 = (df3.assign(to_sort = df3.stemmed_smallest_index.abs()).sort_values('to_sort').drop_duplicates('documentnr').drop(columns='to_sort'))\n",
    "    df3 = df3[np.isfinite(df3['stemmed_smallest_index'])]\n",
    "    df1 = get_data()\n",
    "    df = pd.merge(df1, df2, how= 'left', on = 'documentnr')\n",
    "    df = pd.merge(df, df3, how = 'left', on='documentnr')\n",
    "    df['topic_label_dictionary'].fillna(value='Overige', inplace = True)\n",
    "    df['len matches'] = df['len matches'].fillna(0)\n",
    "    df['stemmed_topic_label_dictionary'].fillna(value='Overige', inplace = True)\n",
    "    df['stemmed_len matches'] = df['stemmed_len matches'].fillna(0)\n",
    "    return df\n",
    "\n",
    "def recode_dictionary():\n",
    "    '''recode categories so to match Bjorns' scoring'''\n",
    "    \n",
    "    df = get_merged_df()\n",
    "    a = ['Buitenlandse handel' , 'Kunst, cultuur en entertainment' ,'*** Sport', 'Ruimtelijke ordening, publiek natuur- en waterbeheer', 'Toegevoegde codes voor media'] \n",
    "    b = ['Overige' ] * len(a)\n",
    "    overige_cat = dict(zip(a,b))\n",
    "    \n",
    "    df['main_topic_label'].replace(overige_cat, inplace = True)\n",
    "    df['topic_label_dictionary'].replace(overige_cat, inplace = True)\n",
    "    df['stemmed_topic_label_dictionary'].replace(overige_cat, inplace = True)\n",
    "    \n",
    "    logger.info(\"the length of categories identified by dict is now: {} \".format(len(df['topic_label_dictionary'].unique()) ) )\n",
    "    logger.info(\"...and the stemmed dict: {} \".format(len(df['stemmed_topic_label_dictionary'].unique()) ) )\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_minnummatches():\n",
    "    \n",
    "    ''' specify how many words should match before the topic is considered present'''\n",
    "    df = recode_dictionary()\n",
    "    df['topic_label_dictionary_minmatches'] = np.where(df['len matches'] < MINNUMBERMATCHES, 'Overige', df['topic_label_dictionary'])\n",
    "    df['topic_label_dictionary_minmatches_stem'] = np.where(df['stemmed_len matches'] < MINNUMBERMATCHES, 'Overige', df['stemmed_topic_label_dictionary'])\n",
    "    return df\n",
    "\n",
    "def get_tp_fp_fn():\n",
    "    \n",
    "    '''create columns with true postives, false positives, and false negatives'''\n",
    "    \n",
    "    df = apply_minnummatches()\n",
    "    topics = list(df['main_topic_label'].unique())\n",
    "    \n",
    "    for topic in topics:\n",
    "        columnname_tp = \"_tp \" + str(topic)\n",
    "        columnname_fp = \"_fp \" + str(topic)\n",
    "        columnname_fn = \"_fn \" + str(topic)\n",
    "        \n",
    "        # and for stemmed\n",
    "        \n",
    "        columnname_tp_st = \"st_tp \" + str(topic)\n",
    "        columnname_fp_st = \"st_fp \" + str(topic)\n",
    "        columnname_fn_st = \"st_fn \" + str(topic)\n",
    "        \n",
    "        # true positives = dictionary correctly identified.\n",
    "        df[columnname_tp] = np.where( (df['main_topic_label'] == topic) & (df['topic_label_dictionary_minmatches'] == topic) , 1, 0 )\n",
    "        # false positive = dictionary identified, but golden standard not. \n",
    "        df[columnname_fp] = np.where( (df['main_topic_label'] != topic) & (df['topic_label_dictionary_minmatches'] == topic) , 1, 0 )\n",
    "        # false negative = dictionary NOT identified, but golden standard DID identify \n",
    "        df[columnname_fn] = np.where( (df['main_topic_label'] == topic) & (df['topic_label_dictionary_minmatches'] != topic) , 1, 0 )\n",
    "        \n",
    "        # and for stemmed:   \n",
    "        df[columnname_tp_st] = np.where( (df['main_topic_label'] == topic) & (df['topic_label_dictionary_minmatches_stem'] == topic) , 1, 0 )\n",
    "        df[columnname_fp_st] = np.where( (df['main_topic_label'] != topic) & (df['topic_label_dictionary_minmatches_stem'] == topic) , 1, 0 )\n",
    "        df[columnname_fn_st] = np.where( (df['main_topic_label'] == topic) & (df['topic_label_dictionary_minmatches_stem'] != topic) , 1, 0 )\n",
    " \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe\n",
    "#df['n'] = 1\n",
    "#df.groupby(df.main_topic_label).agg({'n' :'sum'})\n",
    "\n",
    "#fig = plt.figure(figsize=(8,6))\n",
    "#df.groupby('topic_label_dictionary_minmatches').text_x.count().sort_values().plot.barh(ylim=0, title= 'N ANNOTATIONS PER CATEGORY\\n')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall_precision():\n",
    "    topics = list(df['main_topic_label'].unique())\n",
    "    \n",
    "    true_positives = [\"_tp \" + str(i) for i in topics]\n",
    "    false_positives = [\"_fp \" + str(i) for i in topics]\n",
    "    false_negatives = [\"_fn \" + str(i) for i in topics]\n",
    "    \n",
    "    true_positives_st = [\"st_tp \" + str(i) for i in topics]\n",
    "    false_positives_st = [\"st_fp \" + str(i) for i in topics]\n",
    "    false_negatives_st = [\"st_fn \" + str(i) for i in topics]\n",
    "   \n",
    "    recall = {}\n",
    "    precision = {}\n",
    "    \n",
    "    recall_stemmed = {}\n",
    "    precision_stemmed = {}\n",
    "    \n",
    "    for tp, fp, fn, st_tp, st_fp, st_fn, topic in zip(true_positives, false_positives, false_negatives, true_positives_st, false_positives_st, false_negatives_st, topics) :   \n",
    "        \n",
    "        recall['recall ' + str(topic)] = df[tp].sum(axis=0) / ( df[tp].sum(axis=0) + df[fn].sum(axis=0) )\n",
    "        precision['precision ' + str(topic)] = df[tp].sum(axis=0) / ( df[tp].sum(axis=0) + df[fp].sum(axis=0) )\n",
    "        \n",
    "        recall_stemmed['recall ' + str(topic)] = df[st_tp].sum(axis=0) / ( df[st_tp].sum(axis=0) + df[st_fn].sum(axis=0) )\n",
    "        precision_stemmed['precision ' + str(topic)] = df[st_tp].sum(axis=0) / ( df[st_tp].sum(axis=0) + df[st_fp].sum(axis=0) )\n",
    "\n",
    "    recall['recall total'] = sum(recall.values()) / len(recall.values())\n",
    "    precision['precision total'] = sum(precision.values()) / len(precision.values())\n",
    "    recall_stemmed['recall total'] = sum(recall_stemmed.values()) / len(recall_stemmed.values())\n",
    "    precision_stemmed['precision total'] = sum(precision_stemmed.values()) / len(precision_stemmed.values())\n",
    "    \n",
    "    return recall, precision, recall_stemmed, precision_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py:7116: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py:7116: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "# get final df:\n",
    "df = get_tp_fp_fn()\n",
    "# check whether all went ok\n",
    "df[df['main_topic_label'] == 'Overige'][['main_topic_label', 'topic_label_dictionary_minmatches', '_tp Overige', '_fp Overige', '_fn Overige']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(PATH_TO_DATA + 'all_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documentnr</th>\n",
       "      <th>main_topic_label</th>\n",
       "      <th>origin</th>\n",
       "      <th>text_x</th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>topic_label_dictionary</th>\n",
       "      <th>index_words</th>\n",
       "      <th>smallest_index</th>\n",
       "      <th>len matches</th>\n",
       "      <th>...</th>\n",
       "      <th>_fn Wetenschappelijk onderzoek, technologie en communicatie</th>\n",
       "      <th>st_tp Wetenschappelijk onderzoek, technologie en communicatie</th>\n",
       "      <th>st_fp Wetenschappelijk onderzoek, technologie en communicatie</th>\n",
       "      <th>st_fn Wetenschappelijk onderzoek, technologie en communicatie</th>\n",
       "      <th>_tp None</th>\n",
       "      <th>_fp None</th>\n",
       "      <th>_fn None</th>\n",
       "      <th>st_tp None</th>\n",
       "      <th>st_fp None</th>\n",
       "      <th>st_fn None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [documentnr, main_topic_label, origin, text_x, topic, type, topic_label_dictionary, index_words, smallest_index, len matches, words matches, text_y, stemmed_topic_label_dictionary, stemmed_index_words, stemmed_smallest_index, stemmed_len matches, stemmed_words matches, stemmed_text, topic_label_dictionary_minmatches, topic_label_dictionary_minmatches_stem, _tp Onderwijs, _fp Onderwijs, _fn Onderwijs, st_tp Onderwijs, st_fp Onderwijs, st_fn Onderwijs, _tp Burgerrechten en vrijheden, _fp Burgerrechten en vrijheden, _fn Burgerrechten en vrijheden, st_tp Burgerrechten en vrijheden, st_fp Burgerrechten en vrijheden, st_fn Burgerrechten en vrijheden, _tp Justitie, Rechtspraak, Criminaliteit, _fp Justitie, Rechtspraak, Criminaliteit, _fn Justitie, Rechtspraak, Criminaliteit, st_tp Justitie, Rechtspraak, Criminaliteit, st_fp Justitie, Rechtspraak, Criminaliteit, st_fn Justitie, Rechtspraak, Criminaliteit, _tp Defensie, _fp Defensie, _fn Defensie, st_tp Defensie, st_fp Defensie, st_fn Defensie, _tp Gezondheid, _fp Gezondheid, _fn Gezondheid, st_tp Gezondheid, st_fp Gezondheid, st_fn Gezondheid, _tp Gemeenschapsontwikkeling, huisvestingsbeleid en stedelijke planning, _fp Gemeenschapsontwikkeling, huisvestingsbeleid en stedelijke planning, _fn Gemeenschapsontwikkeling, huisvestingsbeleid en stedelijke planning, st_tp Gemeenschapsontwikkeling, huisvestingsbeleid en stedelijke planning, st_fp Gemeenschapsontwikkeling, huisvestingsbeleid en stedelijke planning, st_fn Gemeenschapsontwikkeling, huisvestingsbeleid en stedelijke planning, _tp Functioneren democratie en openbaar bestuur, _fp Functioneren democratie en openbaar bestuur, _fn Functioneren democratie en openbaar bestuur, st_tp Functioneren democratie en openbaar bestuur, st_fp Functioneren democratie en openbaar bestuur, st_fn Functioneren democratie en openbaar bestuur, _tp Macro-economie en belastingen, _fp Macro-economie en belastingen, _fn Macro-economie en belastingen, st_tp Macro-economie en belastingen, st_fp Macro-economie en belastingen, st_fn Macro-economie en belastingen, _tp Buitenlandse zaken en ontwikkelingssamenwerking, _fp Buitenlandse zaken en ontwikkelingssamenwerking, _fn Buitenlandse zaken en ontwikkelingssamenwerking, st_tp Buitenlandse zaken en ontwikkelingssamenwerking, st_fp Buitenlandse zaken en ontwikkelingssamenwerking, st_fn Buitenlandse zaken en ontwikkelingssamenwerking, _tp Ondernemingen, Bankwezen en binnenlandse handel , _fp Ondernemingen, Bankwezen en binnenlandse handel , _fn Ondernemingen, Bankwezen en binnenlandse handel , st_tp Ondernemingen, Bankwezen en binnenlandse handel , st_fp Ondernemingen, Bankwezen en binnenlandse handel , st_fn Ondernemingen, Bankwezen en binnenlandse handel , _tp Arbeid, _fp Arbeid, _fn Arbeid, st_tp Arbeid, st_fp Arbeid, st_fn Arbeid, _tp Verkeer en vervoer, _fp Verkeer en vervoer, _fn Verkeer en vervoer, st_tp Verkeer en vervoer, st_fp Verkeer en vervoer, st_fn Verkeer en vervoer, _tp Overige, _fp Overige, _fn Overige, st_tp Overige, st_fp Overige, st_fn Overige, _tp sociale Zaken, _fp sociale Zaken, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 140 columns]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['main_topic_label'].astype(str).replace({None: 'Overige'}, inplace=True)\n",
    "df[df['main_topic_label'].astype(str) == None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "#get precision and recall for dictionary items\n",
    "recall, precision, recall_stemmed, precision_stemmed = get_recall_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall Onderwijs -- 0.41901408450704225\n",
      "recall Burgerrechten en vrijheden -- 0.017057569296375266\n",
      "recall Justitie, Rechtspraak, Criminaliteit -- 0.17144808743169399\n",
      "recall Defensie -- 0.19556451612903225\n",
      "recall Gezondheid -- 0.2334293948126801\n",
      "recall Gemeenschapsontwikkeling, huisvestingsbeleid en stedelijke planning -- 0.060109289617486336\n",
      "recall Functioneren democratie en openbaar bestuur -- 0.02122347066167291\n",
      "recall Macro-economie en belastingen -- 0.15767634854771784\n",
      "recall Buitenlandse zaken en ontwikkelingssamenwerking -- 0.032357473035439135\n",
      "recall Ondernemingen, Bankwezen en binnenlandse handel  -- 0.1109375\n",
      "recall Arbeid -- 0.1038961038961039\n",
      "recall Verkeer en vervoer -- 0.10266159695817491\n",
      "recall Overige -- 0.9448740828871703\n",
      "recall sociale Zaken -- 0.01\n",
      "recall Immigratie en integratie -- 0.10038610038610038\n",
      "recall Landbouw en Visserij -- 0.345\n",
      "recall Energiebeleid -- 0.1223021582733813\n",
      "recall Milieu -- 0.07936507936507936\n",
      "recall Wetenschappelijk onderzoek, technologie en communicatie -- 0.022321428571428572\n",
      "recall None -- nan\n",
      "recall total -- nan\n",
      "\n",
      "precision Onderwijs -- 0.6197916666666666\n",
      "precision Burgerrechten en vrijheden -- 0.34782608695652173\n",
      "precision Justitie, Rechtspraak, Criminaliteit -- 0.6952908587257618\n",
      "precision Defensie -- 0.34519572953736655\n",
      "precision Gezondheid -- 0.5510204081632653\n",
      "precision Gemeenschapsontwikkeling, huisvestingsbeleid en stedelijke planning -- 0.6111111111111112\n",
      "precision Functioneren democratie en openbaar bestuur -- 0.5\n",
      "precision Macro-economie en belastingen -- 0.4523809523809524\n",
      "precision Buitenlandse zaken en ontwikkelingssamenwerking -- 0.6461538461538462\n",
      "precision Ondernemingen, Bankwezen en binnenlandse handel  -- 0.44654088050314467\n",
      "precision Arbeid -- 0.43243243243243246\n",
      "precision Verkeer en vervoer -- 0.421875\n",
      "precision Overige -- 0.3687795062301679\n",
      "precision sociale Zaken -- 0.18181818181818182\n",
      "precision Immigratie en integratie -- 0.8125\n",
      "precision Landbouw en Visserij -- 0.696969696969697\n",
      "precision Energiebeleid -- 0.4594594594594595\n",
      "precision Milieu -- 0.5405405405405406\n",
      "precision Wetenschappelijk onderzoek, technologie en communicatie -- 0.43478260869565216\n",
      "precision None -- nan\n",
      "precision total -- nan\n",
      "\n",
      "recall Onderwijs -- 0.602112676056338\n",
      "recall Burgerrechten en vrijheden -- 0.04904051172707889\n",
      "recall Justitie, Rechtspraak, Criminaliteit -- 0.2930327868852459\n",
      "recall Defensie -- 0.3629032258064516\n",
      "recall Gezondheid -- 0.3242074927953891\n",
      "recall Gemeenschapsontwikkeling, huisvestingsbeleid en stedelijke planning -- 0.1092896174863388\n",
      "recall Functioneren democratie en openbaar bestuur -- 0.06367041198501873\n",
      "recall Macro-economie en belastingen -- 0.18464730290456433\n",
      "recall Buitenlandse zaken en ontwikkelingssamenwerking -- 0.0662557781201849\n",
      "recall Ondernemingen, Bankwezen en binnenlandse handel  -- 0.20625\n",
      "recall Arbeid -- 0.32792207792207795\n",
      "recall Verkeer en vervoer -- 0.25665399239543724\n",
      "recall Overige -- 0.877255601824311\n",
      "recall sociale Zaken -- 0.01\n",
      "recall Immigratie en integratie -- 0.25096525096525096\n",
      "recall Landbouw en Visserij -- 0.37\n",
      "recall Energiebeleid -- 0.14388489208633093\n",
      "recall Milieu -- 0.09126984126984126\n",
      "recall Wetenschappelijk onderzoek, technologie en communicatie -- 0.03571428571428571\n",
      "recall None -- nan\n",
      "recall total -- nan\n",
      "\n",
      "precision Onderwijs -- 0.41504854368932037\n",
      "precision Burgerrechten en vrijheden -- 0.04684317718940937\n",
      "precision Justitie, Rechtspraak, Criminaliteit -- 0.604225352112676\n",
      "precision Defensie -- 0.3870967741935484\n",
      "precision Gezondheid -- 0.5890052356020943\n",
      "precision Gemeenschapsontwikkeling, huisvestingsbeleid en stedelijke planning -- 0.7142857142857143\n",
      "precision Functioneren democratie en openbaar bestuur -- 0.4396551724137931\n",
      "precision Macro-economie en belastingen -- 0.419811320754717\n",
      "precision Buitenlandse zaken en ontwikkelingssamenwerking -- 0.593103448275862\n",
      "precision Ondernemingen, Bankwezen en binnenlandse handel  -- 0.45517241379310347\n",
      "precision Arbeid -- 0.43162393162393164\n",
      "precision Verkeer en vervoer -- 0.5172413793103449\n",
      "precision Overige -- 0.41096144914073385\n",
      "precision sociale Zaken -- 0.2857142857142857\n",
      "precision Immigratie en integratie -- 0.5078125\n",
      "precision Landbouw en Visserij -- 0.6727272727272727\n",
      "precision Energiebeleid -- 0.5405405405405406\n",
      "precision Milieu -- 0.5609756097560976\n",
      "precision Wetenschappelijk onderzoek, technologie en communicatie -- 0.3902439024390244\n",
      "precision None -- nan\n",
      "precision total -- nan\n"
     ]
    }
   ],
   "source": [
    "for t, s in recall.items():\n",
    "    print('{} -- {}'.format(t, s))\n",
    "    \n",
    "print()\n",
    "\n",
    "for t, s in precision.items():\n",
    "    print('{} -- {}'.format(t, s))\n",
    "\n",
    "print()\n",
    "\n",
    "    \n",
    "for t, s in recall_stemmed.items():\n",
    "    print('{} -- {}'.format(t, s))\n",
    "    \n",
    "print()\n",
    "\n",
    "for t, s in precision_stemmed.items():\n",
    "    print('{} -- {}'.format(t, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 1014,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['topic_label_dictionary_minmatches'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The following 'value_vars' are not present in the DataFrame: ['topic_label_dictionary_minmatches', 'topic_label_dictionary_minmatches_stem']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-349-627acaa563fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmelted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'main_topic_label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'topic_label_dictionary_minmatches'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'topic_label_dictionary_minmatches_stem'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'manual vs. dictionary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'topic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ax = sns.countplot(y=\"topic\", hue='manual vs. dictionary', \n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/reshape/melt.py\u001b[0m in \u001b[0;36mmelt\u001b[0;34m(frame, id_vars, value_vars, var_name, value_name, col_level)\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0;34m\"The following 'value_vars' are not present in\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0;34m\" the DataFrame: {missing}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 )\n\u001b[1;32m     76\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_vars\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The following 'value_vars' are not present in the DataFrame: ['topic_label_dictionary_minmatches', 'topic_label_dictionary_minmatches_stem']\""
     ]
    }
   ],
   "source": [
    "df['id'] = df.index\n",
    "melted = pd.melt(df, id_vars=['id'], value_vars=['main_topic_label', 'topic_label_dictionary_minmatches','topic_label_dictionary_minmatches_stem'], var_name='manual vs. dictionary', value_name='topic')\n",
    "\n",
    "plt.rcParams['figure.figsize']=(10,10)\n",
    "ax = sns.countplot(y=\"topic\", hue='manual vs. dictionary', \n",
    "                   order = melted['topic'].value_counts().index, data=melted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl['id_number'] = pl['id_number'].astype(str)\n",
    "coder['id_number'] = coder['id_number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder['year'] = coder['year'].fillna(0).astype(int)\n",
    "coder['year'] = coder['year'].astype(str)\n",
    "pl['year'] = pl['year'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(coder, pl, how= 'inner', on = ['year', 'id_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coder[['year', 'id_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1750"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1306.0\n",
       "1       1391.0\n",
       "2       1453.0\n",
       "3        285.0\n",
       "4        798.0\n",
       "         ...  \n",
       "3228    1695.0\n",
       "3229     384.0\n",
       "3230    1543.0\n",
       "3231    1599.0\n",
       "3232     825.0\n",
       "Name: id_number, Length: 1917, dtype: object"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coder['id_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter</th>\n",
       "      <th>file</th>\n",
       "      <th>type</th>\n",
       "      <th>datum</th>\n",
       "      <th>naam</th>\n",
       "      <th>onderwerp</th>\n",
       "      <th>vraag</th>\n",
       "      <th>date</th>\n",
       "      <th>id_number</th>\n",
       "      <th>id_date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [counter, file, type, datum, naam, onderwerp, vraag, date, id_number, id_date, year]\n",
       "Index: []"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl[pl['counter'] == 'ah-tk-19971998-46.xml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pl[pl['year'] == 1996]\n",
    "\n",
    "#pl[(pl['year'] == 1996) & (pl['id_number'] == '993')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>doc_number</th>\n",
       "      <th>id_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996</td>\n",
       "      <td>1306</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996</td>\n",
       "      <td>1391</td>\n",
       "      <td>1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1996</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995</td>\n",
       "      <td>285</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996</td>\n",
       "      <td>798</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1997</td>\n",
       "      <td>1624</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1997</td>\n",
       "      <td>1696</td>\n",
       "      <td>1696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1996</td>\n",
       "      <td>588</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1996</td>\n",
       "      <td>588</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1997</td>\n",
       "      <td>669</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1997</td>\n",
       "      <td>869</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1997</td>\n",
       "      <td>869</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1998</td>\n",
       "      <td>1175</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1997</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1997</td>\n",
       "      <td>375</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1997</td>\n",
       "      <td>421</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1997</td>\n",
       "      <td>ah-tk-19971998-45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1999</td>\n",
       "      <td>ah-tk-19981999-1458</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1999</td>\n",
       "      <td>ah-tk-19981999-1761</td>\n",
       "      <td>1761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1998</td>\n",
       "      <td>ah-tk-19981999-420</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1998</td>\n",
       "      <td>ah-tk-19981999-9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1999</td>\n",
       "      <td>ah-tk-19981999-983</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2000</td>\n",
       "      <td>ah-tk-19992000-1224</td>\n",
       "      <td>1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2000</td>\n",
       "      <td>ah-tk-19992000-1264</td>\n",
       "      <td>1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2000</td>\n",
       "      <td>ah-tk-19992000-1500</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1999</td>\n",
       "      <td>ah-tk-19992000-80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2000</td>\n",
       "      <td>ah-tk-19992000-877</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2001</td>\n",
       "      <td>ah-tk-20002001-1002</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2001</td>\n",
       "      <td>ah-tk-20002001-1127</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2001</td>\n",
       "      <td>ah-tk-20002001-1599</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>2014</td>\n",
       "      <td>ah-tk-20132014-2253</td>\n",
       "      <td>2253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>2014</td>\n",
       "      <td>ah-tk-20132014-1454</td>\n",
       "      <td>1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>2013</td>\n",
       "      <td>ah-tk-20132014-718</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>2014</td>\n",
       "      <td>ah-tk-20142015-366</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>2014</td>\n",
       "      <td>ah-tk-20142015-539</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>2015</td>\n",
       "      <td>ah-tk-20142015-1232</td>\n",
       "      <td>1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>2015</td>\n",
       "      <td>ah-tk-20142015-1232</td>\n",
       "      <td>1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>2015</td>\n",
       "      <td>ah-tk-20142015-3085</td>\n",
       "      <td>3085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>2014</td>\n",
       "      <td>ah-tk-20142015-328</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>2015</td>\n",
       "      <td>ah-tk-20152016-616</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>2016</td>\n",
       "      <td>ah-tk-20152016-1522</td>\n",
       "      <td>1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>2016</td>\n",
       "      <td>ah-tk-20152016-2269</td>\n",
       "      <td>2269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>2016</td>\n",
       "      <td>ah-tk-20152016-1576</td>\n",
       "      <td>1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>2016</td>\n",
       "      <td>ah-tk-20152016-2819</td>\n",
       "      <td>2819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>2017</td>\n",
       "      <td>ah-tk-20162017-1682</td>\n",
       "      <td>1682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>2016</td>\n",
       "      <td>ah-tk-20162017-694</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>2016</td>\n",
       "      <td>ah-tk-20162017-613</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>2017</td>\n",
       "      <td>ah-tk-20162017-1520</td>\n",
       "      <td>1520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>2017</td>\n",
       "      <td>ah-tk-20162017-2019</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>1996</td>\n",
       "      <td>ah-tk-19951996-1208</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>1995</td>\n",
       "      <td>ah-tk-19951996-1420</td>\n",
       "      <td>1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>1996</td>\n",
       "      <td>ah-tk-19951996-857</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>1995</td>\n",
       "      <td>ah-tk-19951996-765</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>1996</td>\n",
       "      <td>ah-tk-19951996-1145</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>1997</td>\n",
       "      <td>ah-tk-19961997-749</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>1997</td>\n",
       "      <td>ah-tk-19961997-1695</td>\n",
       "      <td>1695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>1996</td>\n",
       "      <td>ah-tk-19961997-384</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>1997</td>\n",
       "      <td>ah-tk-19961997-1543</td>\n",
       "      <td>1543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>1997</td>\n",
       "      <td>ah-tk-19961997-1599</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>1998</td>\n",
       "      <td>ah-tk-19971998-825</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year           doc_number id_number\n",
       "0     1996                 1306      1306\n",
       "1     1996                 1391      1391\n",
       "2     1996                 1453      1453\n",
       "3     1995                  285       285\n",
       "4     1996                  798       798\n",
       "...    ...                  ...       ...\n",
       "2058  1997  ah-tk-19961997-1695      1695\n",
       "2059  1996   ah-tk-19961997-384       384\n",
       "2060  1997  ah-tk-19961997-1543      1543\n",
       "2061  1997  ah-tk-19961997-1599      1599\n",
       "2062  1998   ah-tk-19971998-825       825\n",
       "\n",
       "[2063 rows x 3 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['year', 'doc_number', 'id_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28058"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pl)\n",
    "57892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dataframe, transformed: grouped by document and only the max length matches\n",
    "#idx = df2.groupby(['documentnr'], sort=False)['len matches'].transform(max) == df2['len matches']\n",
    "#df2[idx].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
